<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>📚 Technical docs &mdash; NeuralDE 1.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=8d563738"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="💡 Theory Overview" href="theory_overview.html" />
    <link rel="prev" title="📖 Guidelines:" href="guidelines.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            NeuralDE
          </a>
              <div class="version">
                1.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="guidelines.html">📖 Guidelines:</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">📚 Technical docs</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="theory_overview.html">💡 Theory Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_de.html">👨‍💻 neural_de package</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">🔄 Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NeuralDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">📚 Technical docs</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tech_docs.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="technical-docs">
<span id="doc-techniques"></span><h1>📚 Technical docs<a class="headerlink" href="#technical-docs" title="Link to this heading"></a></h1>
<p>The classes of neuralde are simple to use. Create an instance and apply the method <code class="xref py py-func docutils literal notranslate"><span class="pre">transform()</span></code>.
The prediction methods from the documentations ensures the
compliance of models from various ML/DL libraries (such as Keras and scikit-learn) to <strong>neuralde</strong>.</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._transformation.</span></span><span class="sig-name descname"><span class="pre">BaseTransformation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_transformation.html#BaseTransformation"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Parent class for any transformation methods of the library.
Provides the methods for logging and input validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – logging.logger. It is recommended to use the Confiance one, obtainable with
neural_de.utils.get_logger(…)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._brightness_enhancer.</span></span><span class="sig-name descname"><span class="pre">BrightnessEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_brightness_enhancer.html#BrightnessEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>BaseTransformation method for image brightness change.
It uses NPLIE-based method for brightness enhancement, and Opencv for transforming the
image.</p>
<dl>
<dt>Example :</dt><dd><p>See the notebook <cite>examples/BrightnessEnhancer_example.ipynb</cite> for more usage details.</p>
<p>1- Import the class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neural_de.transformations</span> <span class="kn">import</span> <span class="n">BrightnessEnhancer</span>
</pre></div>
</div>
<p>2- Create an instance of BrightnessEnhancer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bright_ehn</span> <span class="o">=</span> <span class="n">BrightnessEnhancer</span><span class="p">()</span>
</pre></div>
</div>
<p>3- Apply the brightness change to a batch of images to a given shape</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out_images</span> <span class="o">=</span> <span class="n">bright_ehn</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – <p>It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…).</p>
<blockquote>
<div><p>If None, one logging with stdout will be provided.</p>
</div></blockquote>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._centered_zoom.</span></span><span class="sig-name descname"><span class="pre">CenteredZoom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keep_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_centered_zoom.html#CenteredZoom"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>CenteredZoom image transformation based on a numpy implementation.
Given a batch of 3-channels image of size width x height, return the centered tile of size
width*keep_ratio x height*keep_ratio.
This transformation does not perform any resolution enhancement of the returned content.
See ResolutionEnhancer to perform both crop and resolution enhancement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keep_ratio</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The proportion of the input image we keep. Must be in ]0,1[.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._derain_enhancer.</span></span><span class="sig-name descname"><span class="pre">DeRainEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_derain_enhancer.html#DeRainEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Provides a rain removal image transformation using the GT-Rain Derain Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._desnow_enhancer.</span></span><span class="sig-name descname"><span class="pre">DeSnowEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_desnow_enhancer.html#DeSnowEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Snow Removal Enhancer, Prenet based implementation.</p>
<p>** WARNING ** : The current method may have bad results on real images. The model had been trained
on a simulated dataset, thus if the dataset is so different of the trained dataset, the results are not guaranteed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> – Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._kernel_deblurring_enhancer.</span></span><span class="sig-name descname"><span class="pre">KernelDeblurringEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'high'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_kernel_deblurring_enhancer.html#KernelDeblurringEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Kernel Deblurring image transformation based on OpenCv implementation. Provides pre-set
filter of medium and high intensity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – <code class="docutils literal notranslate"><span class="pre">high</span></code> or <code class="docutils literal notranslate"><span class="pre">medium</span></code>: use a pre-set kernel with high or medium intensity.</p></li>
<li><p><strong>custom</strong> – Optional, custom kernel to use. It can be any non empty 2D matrix. If provided,
the value of <cite>kernel</cite> will not be used.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._night_image_enhancer.</span></span><span class="sig-name descname"><span class="pre">NightImageEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_night_image_enhancer.html#NightImageEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Provides Night to Day image transformation using the MAXIM model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._resolution_enhancer.</span></span><span class="sig-name descname"><span class="pre">ResolutionEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_resolution_enhancer.html#ResolutionEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>BaseTransformation method for image resolution change.
It uses neural-based method for resolution enhancement, and Opencv for diminishing the
resolution.</p>
<dl>
<dt>Example :</dt><dd><p>See the notebook <cite>examples/ResolutionEnhancer_example.ipynb</cite> for more usage details.</p>
<p>1- Import the class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neural_de.transformations</span> <span class="kn">import</span> <span class="n">ResolutionEnhancer</span>
</pre></div>
</div>
<p>2- Create an instance of ResolutionEnhancer.
<code class="docutils literal notranslate"><span class="pre">device</span> <span class="pre">=&quot;Cuda&quot;</span></code> is recommended if you have a gpu and torch with cuda enabled.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">res_shift</span> <span class="o">=</span> <span class="n">ResolutionEnhancer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>3- Apply the resolution change to a batch of images to a given shape</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out_images</span> <span class="o">=</span> <span class="n">res_shift</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Any torch-compatible device string.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the Confiance logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._transformation_pipeline.</span></span><span class="sig-name descname"><span class="pre">TransformationPipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_transformation_pipeline.html#TransformationPipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Provides a pipeline object, to facilitate the automation of multiple transformations methods,
and/or offer loading from a yaml file.</p>
<p>You can check the example notebook <strong>examples/Pipeline_example.ipynb</strong> for details on the syntax
and usage.
An example of valid config file can be found in <strong>examples/config/conf_user.yaml</strong></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code>]) – either a path toward a yaml configuration file, or a list of dict.</p></li>
<li><p><strong>logger</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]) – It is recommended to use the confiance.ai logger, obtainable with
neural_de.utils.get_logger(…). If None, one logging with stdout will be provided.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_de.transformations._diffusion._diffusion_enhancer.</span></span><span class="sig-name descname"><span class="pre">DiffusionEnhancer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DiffPureConfig(weights_path=PosixPath('/home/jovyan/.neuralde/diffpure/256x256_diffusion_uncond.pt'),</span> <span class="pre">img_shape=(3,</span> <span class="pre">256,</span> <span class="pre">256),</span> <span class="pre">attention_resolutions=[32,</span> <span class="pre">16,</span> <span class="pre">8],</span> <span class="pre">num_classes=None,</span> <span class="pre">dims=2,</span> <span class="pre">learn_sigma=True,</span> <span class="pre">num_channels=256,</span> <span class="pre">num_head_channels=64,</span> <span class="pre">num_res_blocks=2,</span> <span class="pre">resblock_updown=True,</span> <span class="pre">use_fp16=True,</span> <span class="pre">use_scale_shift_norm=True,</span> <span class="pre">num_heads=4,</span> <span class="pre">num_heads_upsample=-1,</span> <span class="pre">channel_mult=None,</span> <span class="pre">dropout=0.0,</span> <span class="pre">use_new_attention_order=False,</span> <span class="pre">t=150,</span> <span class="pre">t_delta=15,</span> <span class="pre">use_bm=False,</span> <span class="pre">use_checkpoint=False,</span> <span class="pre">conv_resample=True,</span> <span class="pre">sample_step=1,</span> <span class="pre">rand_t=False)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neural_de/transformations/_diffusion/_diffusion_enhancer.html#DiffusionEnhancer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>The goal of this class is to purify a batch of images, to reduce noise and to increase
robustness against potential adversarial attacks contained in the images. The weights given in
this librairy are adapted for an output in 256*256 format. Of course, all sizes are
supported in input but the enhancer will resize the images to 256*256.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">DeviceObjType</span></code>]) – some steps can be computed with cpu but a gpu is highly recommended.</p></li>
<li><p><strong>config</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="neural_de_transformations.html#neural_de.transformations._diffusion._diffpure_config.DiffPureConfig" title="neural_de.transformations._diffusion._diffpure_config.DiffPureConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiffPureConfig</span></code></a>]) – an instance of the DiffPureConfig class. The most important attributes are: t,
sample_step and t_delta. Higher t or sample step will lead to a stronger denoising, at
the cost of processing time. t_delta is the quantity of noise added by the method before
it’s diffusion process : the higher, the higher the chances to remove adversarial attacks,
at the cost of a potentiel loss of quality in the images.
The other attributes of DiffPureConfig should be modified for a custom
Diffusion model.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p>The neuralDE library provides several methods to preprocess images.
To understand how to use these methods, click on the link to see the following notebooks.
Please refer to the notebooks in ./examples to for working examples:</p>
<div class="toctree-wrapper compound">
</div>
<p>Brightness_Enhancer (This method allows us to brighten images.)
<a class="reference internal" href="examples/Brightness_Enhancered_examples.html"><span class="doc">Notebook Brightness Enhancered</span></a></p>
<p>CenteredZoom (This method allows us to zoom on the center of images.)
<a class="reference internal" href="examples/CenteredZoom_example.html"><span class="doc">Notebook Centered Zoom</span></a></p>
<p>Derain_Enhancer (This method allows us to remove the rain on images.)
<a class="reference internal" href="examples/DeRainEnhancer_example.html"><span class="doc">Notebook DeRain Enhancer</span></a></p>
<p>Desnow_Enhancer (This method allows us to remove the snow on images.)
<a class="reference internal" href="examples/SnowRemoval.html"><span class="doc">Notebook DeSnow Enhancer</span></a></p>
<p>Kernel_Deblurring_Enhancer (This method allows us to deblur the images.)
<a class="reference internal" href="examples/KernelDeblurringEnhancer.html"><span class="doc">Notebook Kernel Deblurring</span></a></p>
<p>Night_Image_Enhancer (This method allows us to improve the clarity of night images.)
<a class="reference internal" href="examples/NightEnhancer_example.html"><span class="doc">Notebook Night Enhancer</span></a></p>
<p>Resolution_Enhancer (This method allows us to increase the resolution of an zoomed image.)
<a class="reference internal" href="examples/ResolutionEnhancer_example.html"><span class="doc">Notebook Resolution Enhancer</span></a></p>
<p>Diffusion_Enhancer (This method allows us to purify noise into images.)
<a class="reference external" href="./examples/DiffpurEnhancer_example.ipynb">Notebook Diffusion Enhancer</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="guidelines.html" class="btn btn-neutral float-left" title="📖 Guidelines:" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="theory_overview.html" class="btn btn-neutral float-right" title="💡 Theory Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Nelson Fernandez Pinto.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>